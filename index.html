<!DOCTYPE html>
<html>

<head>
    <style>
        font: Arial;
    </style>
</head>

<body>
    <h1>Spark Installation with Cache Intersystems on Windows</h1>
    <div>
        <h2>Files to download</h2>
        <ol>
            <li>Download Spark from the official website -
                <a ref="https://spark.apache.org/downloads.html">https://spark.apache.org/downloads.html</a>
            </li>
            <li>Download Java 1.8+ JRE/SDK</li>
            <li>Download winutils.exe from
                <a href="https://github.com/steveloughran/winutils">https://github.com/steveloughran/winutils</a>. Make sure Hadoop version is compatible with Spark.</li>
            <li>Download msvcp100.dll and msvcp110.dll (for winutils.exe to run)
                <ol type="i">
                    <li>x86:
                        <a href="http://www.microsoft.com/en-us/download/details.aspx?id=5555">http://www.microsoft.com/en-us/download/details.aspx?id=5555</a>
                    </li>
                    <li>x64:
                        <a href="http://www.microsoft.com/en-us/download/details.aspx?id=14632">http://www.microsoft.com/en-us/download/details.aspx?id=14632</a>
                    </li>
                </ol>
            </li>
        </ol>

        <h2>Installation</h2>
        <ol>
            <li>Extract Spark to any folder - e.g. C:\spark-{version}</li>
            <li>Install Java</li>
            <li>Extract winutils to any folder - e.g. C:\winutils</li>
            <li>Install msvcp100.dll and msvcp110.dll</li>
        </ol>

        <h2>Set Environment Variable</h2>

        <ol>
            <li>Right click on Computer/This PC -> Prperties -> Advanced system settings</li>
            <li>Click on Environment Variables...</li>
            <li>Create new variable. Click New...
                <ol type="i">
                    <li>Spark - Variable name: SPARK_HOME, Variable value: C:\spark-{version}</li>
                    <li>Java - Variable name: JAVA_HOME, Variable value: C:\Program Files\Java\{java version}</li>
                    <li>Hadoop - Variable name: HADOOP_HOME, Variable value: C:\winutils</li>
                </ol>
            </li>
            <li>Edit PATH by appending this to the current line:
                <br> ;%SPARK_HOME%\bin;%HADOOP_HOME%\bin
            </li>
            <li>Create hive folder C:\tmp\hive</li>
            <li>Run cmd as Administrator, then type this:
                <br> winutils.exe chmod 777 C:\tmp\hive
            </li>
        </ol>

        <h2>Testing Installation</h2>

        <ol>
            <li>Open Command Line (cmd) or Powershell (PS), try this command -> winutils.exe ls -F C:\tmp\hive</li>
            <li>You should be getting this, make sure the prefix is display as drwxrwxrwx (means it readable/executable/writable
                by anyone)
                <br> drwxrwxrwx|1|BUILTIN\Administrators|WIN-T4EK3AMKQL0\None|0|May| 4|2018|C:\tmp\hive
            </li>
            <li>
                Then run Spark in cmd/PS by typing spark-shell
            </li>
            <li>If you getting this message, ignore it:
                <br> {Date} {Time} WARN General: Plugin (Bundle) "org.datanucleus"...
            </li>
            <li>
                Enter this command: spark.range(1).withColumn("status", lit("All seems fine. Congratulations!")).show(false)
            </li>
            <li>
                And you should be getting this:
                <br> +---+--------------------------------+
                <br> |id |status |
                <br> +---+--------------------------------+
                <br> |0 |All seems fine. Congratulations!|
                <br> +---+--------------------------------+
                <br>
            </li>
        </ol>

        <h2>Setting up Spark connection to Cache</h2>
        <span>If using spark-shell:</span>
        <ol>
            <li>Copy cache-jdbc-2.0.0.jar and cache-spark-2.0.0.jar to Spark jars folder, e.g. C:\spark\jars</li>
            <li>Run this command to import Cache libraries. If this fail, then make sure the jars are copied correctly.
                <br> import com.intersys.jdbc._
                <br> import com.intersys.spark._
                <br>
            </li>
            <li>Read one of the table in Cache:
                <br> val df = spark.read
                <br> ;&nbsp;&nbsp; .option("url","Cache://7.7.7.129:1972/USER/spark-jdbc.log") // the path to Cache in format
                => Cache://{IP Address}:{Port}/{NAMESPACE}/{log file path}
                <br> ;&nbsp;&nbsp; .option("user","_SYSTEM") // Username of CACHE
                <br> ;&nbsp;&nbsp; .option("password","SYS") // Password of CACHE
                <br> ;&nbsp;&nbsp; .Cache("SampleTable") // Table Name in Cache
                <br> df.show()
            </li>
            <li>If result is shown, congratulations!</li>
        </ol>

        <span>If using Java Gateway in Cache:</span>
        <ol>
            <li>Custom jar must be created for gateway to interact with Spark.</li>
        </ol>

        <h2>Running Cluster Mode</h2>
        <span>**Take note that you need to install Spark first on both master and slaves**</span>
        <ol>
            <li>For master, open cmd/PS and enter this command:
                <br> spark-class org.apache.spark.deploy.master.Master
            </li>
            <li>Then check if the master is running. Just open this link
                <a href="http://localhost:8080/"></a>http://localhost:8080/</li>
            <li>Jot down the spark master address e.g. spark://7.7.7.129:7077</li>
            <li> For each of the slaves, open cmd/PS and enter this command:
                <br> spark-class org.apache.spark.deploy.worker.Worker spark://7.7.7.129:7077 --memory 3G --cores 2
            </li>
            <li>Verify slaves is running in master in browser
                <a href="http://localhost:8080/">http://localhost:8080/</a>
            </li>
            <li>Run spark-shell using this command:
                <br> spark-shell --master spark://7.7.7.129:7077 --executor-memory 3G
            </li>
            <li>Run your application from here</li>
        </ol>
    </div>
</body>

</html>